{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75a300c8",
   "metadata": {},
   "source": [
    "# Manual Evaluation of POLAR Dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfde60d5",
   "metadata": {},
   "source": [
    "## 1 Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38959af",
   "metadata": {},
   "source": [
    "### 1.1 Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "041c3a8f",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from numpy import linalg\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import time\n",
    "from random import shuffle\n",
    "import sys\n",
    "import nltk \n",
    "from nltk.corpus import wordnet \n",
    "import gc\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import plotly\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "from functools import partial\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output\n",
    "from ipywidgets import IntProgress\n",
    "from random import randint\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "import torch\n",
    "\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "\n",
    "from gensim.test.utils import datapath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6b974e",
   "metadata": {},
   "source": [
    "### 1.2 Import Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6915d4be",
   "metadata": {},
   "source": [
    "Import the embedding file you want to use for the testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75bcf97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import embedding for analysis, need to do analysis for every combiantion of pre-trained model and antonyms used 8 in total\n",
    "company_df = pd.read_csv('../data/processed/POLAR-GloVeWiki-bus-antonyms-inter.csv')\n",
    "#Also input the embedding name and antonym set used here to get right file names in the end,\n",
    "#bus=business antonym set we created, org=original antonyms used by POLAR paper\n",
    "embedding_name = 'GloVeWiki_bus'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06d3ceb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose 10 companies that are in all embeddings for analysis\n",
    "#exchange for common-10-companies-google file when using googlenews embeddings\n",
    "with open(\"../data/processed/common-10-companies\", \"rb\") as fp:  \n",
    "    b = pickle.load(fp)\n",
    "    \n",
    "analysis_df = company_df.loc[company_df['Unnamed: 0'].isin(b)]\n",
    "df_names = analysis_df['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256c9dcd",
   "metadata": {},
   "source": [
    "## 2 POLAR Embedding Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4549b14b",
   "metadata": {},
   "source": [
    "### 2.1 Create Test Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65310076",
   "metadata": {},
   "source": [
    "Functions for creating the test setup are defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b681edba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create function that handles the POLAR pair search\n",
    "def get_important_pairs(df, number, name):\n",
    "    #get the number of highest absolute values\n",
    "    imp_row = df.loc[df['Unnamed: 0']==name]\n",
    "    imp_row = imp_row.loc[:,imp_row.columns!='Unnamed: 0']\n",
    "    imp_columns = imp_row.abs().values.argsort(1)[:, -number:][:, ::-1][0]\n",
    "    #get the column names\n",
    "    column_names=[]\n",
    "    column_list=imp_row.columns.values.tolist()\n",
    "    for i in imp_columns:\n",
    "        nam=column_list[i]\n",
    "        column_names.append(nam)\n",
    "    value_list=[]\n",
    "    for item in column_names:\n",
    "        value_list.append(imp_row[item].values)\n",
    "    ret_df=pd.DataFrame(column_names)\n",
    "    ret_df.columns=['top_polar_dim']\n",
    "    ret_df['top_value']=value_list\n",
    "    imp_columns_down=imp_row.abs().values.argsort(1)[:, :number][:, ::-1][0]\n",
    "    down_column_names=[]\n",
    "    down_value_list=[]\n",
    "    for i in imp_columns_down:\n",
    "        nam=column_list[i]\n",
    "        down_column_names.append(nam)\n",
    "        down_value_list.append(imp_row[nam].values)\n",
    "    ret_df['down_polar_dim']=down_column_names\n",
    "    ret_df['down_value']=down_value_list\n",
    "    \n",
    "    return ret_df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea3d62dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataset for the test\n",
    "def create_polar_intruder_dataset(number,bus_df,name):\n",
    "    company_data=get_important_pairs(bus_df,number,name)\n",
    "    rand_list=[]\n",
    "    pos_list=[]\n",
    "    name_list=[]\n",
    "    k = random.randint(0, number-1)\n",
    "    for i in range(number):\n",
    "        if i==k:\n",
    "            rand_list.append(company_data['down_polar_dim'].loc[i])\n",
    "            pos_list.append(k)\n",
    "            name_list.append(name)\n",
    "        else:\n",
    "            rand_list.append(company_data['top_polar_dim'].loc[i])\n",
    "            pos_list.append(k)\n",
    "            name_list.append(name)\n",
    "    company_data['random']= rand_list\n",
    "    company_data['name'] = name_list\n",
    "    company_data['position'] = pos_list\n",
    "    return company_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19b28140",
   "metadata": {},
   "outputs": [],
   "source": [
    "#handle intruder creation outside\n",
    "def create_polar_test_intruder_dataset(df):\n",
    "    intruder_list=[]\n",
    "    for bus in df:\n",
    "        lst=create_polar_intruder_dataset(5,company_df,bus)\n",
    "        intruder_list.append(lst)\n",
    "    intruder_list= pd.concat(intruder_list, ignore_index=True)\n",
    "    return intruder_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b487d0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create function for the test execution\n",
    "def polar_intrusion_test(df_intruder,name):\n",
    "\n",
    "    max_count = df_intruder.shape[0]\n",
    "    global i\n",
    "    i = 0\n",
    "    \n",
    "    button_0 = widgets.Button(description = df_intruder['random'].loc[i])\n",
    "    button_1 = widgets.Button(description = df_intruder['random'].loc[i+1])\n",
    "    button_2 = widgets.Button(description = df_intruder['random'].loc[i+2])\n",
    "    button_3 = widgets.Button(description = df_intruder['random'].loc[i+3])\n",
    "    button_4 = widgets.Button(description = df_intruder['random'].loc[i+4])\n",
    "    \n",
    "    global chosen_positions\n",
    "    chosen_positions=[]\n",
    "    \n",
    "    display(\"Polar Intrusion Text\")\n",
    "    \n",
    "    f = IntProgress(min=0, max=max_count)    \n",
    "    display(f)\n",
    "    \n",
    "    display(df_intruder['name'].loc[i])\n",
    "\n",
    "    display(button_0)\n",
    "    display(button_1)\n",
    "    display(button_2)\n",
    "    display(button_3)\n",
    "    display(button_4)\n",
    "    \n",
    "    def btn_eventhandler(position, obj):\n",
    "        global i \n",
    "        i += 5\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "            \n",
    "        display(\"Polar Intrusion Text\")\n",
    "        display(f)\n",
    "        f.value += 5\n",
    "        \n",
    "        global chosen_positions\n",
    "        chosen_positions+=  5*[position]\n",
    "                \n",
    "        if i < max_count:\n",
    "            \n",
    "            display(df_intruder['name'].loc[i])\n",
    "\n",
    "            button_0 = widgets.Button(description = df_intruder['random'].loc[i])\n",
    "            button_1 = widgets.Button(description = df_intruder['random'].loc[i+1])\n",
    "            button_2 = widgets.Button(description = df_intruder['random'].loc[i+2])\n",
    "            button_3 = widgets.Button(description = df_intruder['random'].loc[i+3])\n",
    "            button_4 = widgets.Button(description = df_intruder['random'].loc[i+4])\n",
    "            \n",
    "            display(button_0)\n",
    "            display(button_1)\n",
    "            display(button_2)\n",
    "            display(button_3)\n",
    "            display(button_4)\n",
    "            \n",
    "            button_0.on_click(partial(btn_eventhandler,0))\n",
    "            button_1.on_click(partial(btn_eventhandler,1))\n",
    "            button_2.on_click(partial(btn_eventhandler,2))\n",
    "            button_3.on_click(partial(btn_eventhandler,3))\n",
    "            button_4.on_click(partial(btn_eventhandler,4))\n",
    "            \n",
    "        else:\n",
    "            print (\"Thanks \" + name + \" you finished all the work!\")\n",
    "            #df_intruder['chosen_word'] = chosen_words\n",
    "            df_intruder['chosen_position'] = chosen_positions\n",
    "            df_intruder.to_csv(\"/Users/stjepankusenic/POLAR_WEBE/data/external/polar_intrusion_test_\" + name +'_'+ embedding_name + \"_results\" + \".csv\", index = False)\n",
    "                \n",
    "    button_0.on_click(partial(btn_eventhandler,0))\n",
    "    button_1.on_click(partial(btn_eventhandler,1))\n",
    "    button_2.on_click(partial(btn_eventhandler,2))\n",
    "    button_3.on_click(partial(btn_eventhandler,3))\n",
    "    button_4.on_click(partial(btn_eventhandler,4))\n",
    "\n",
    "    \n",
    "    return df_intruder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb87163b",
   "metadata": {},
   "source": [
    "### 2.2 Test Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac12dbd3",
   "metadata": {},
   "source": [
    "Execute the test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ece5267e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test =create_polar_test_intruder_dataset(df_names)\n",
    "#change the name to your first name!\n",
    "#df_test1 =polar_intrusion_test(df_test,'Stjepan')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f3ed67",
   "metadata": {},
   "source": [
    "### 2.3 Evaluate the Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea18be8",
   "metadata": {},
   "source": [
    "Here we want to see how the annotators performed in testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87f3691d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the test files you want to analyze\n",
    "data1 = pd.read_csv('../data/external/Coder-Evaluation-POLAR-dim/Sree-eval/polar_intrusion_test_Sreehari_GloVeWiki_org_results.csv')\n",
    "data2 = pd.read_csv('../data/external/Coder-Evaluation-POLAR-dim/Xho_eval/polar_intrusion_test_Xhoana_GloVeWiki_org_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a208f3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function that handles the evealuation\n",
    "def test_evaluation(df1,df2,number,name1, name2):\n",
    "    master_list1 = [name1]\n",
    "    master_list2 = [name2]\n",
    "    max_count= df1.shape[0]\n",
    "    list1=[]\n",
    "    list2=[]\n",
    "    for i in range(number):\n",
    "        list1.append(df1.loc[i*5])\n",
    "        list2.append(df2.loc[i*5])\n",
    "    df1= pd.DataFrame(list1)\n",
    "    df2= pd.DataFrame(list2)\n",
    "    df_both=pd.concat([df1,df2])\n",
    "    f21=f1_score(df1['chosen_position'], df1['position'], average='weighted')\n",
    "    print('F1 Score Coder 1:',f21)\n",
    "    master_list1.append(f21)\n",
    "    f22=f1_score(df2['chosen_position'], df2['position'], average='weighted')\n",
    "    print('F1 Score Coder 2:',f22)\n",
    "    master_list2.append(f22)\n",
    "    print( )\n",
    "    accuracy_score1=accuracy_score(df1['chosen_position'], df1['position'])\n",
    "    print('Accuracy Score Coder 1:',accuracy_score1)\n",
    "    master_list1.append(accuracy_score1)\n",
    "    accuracy_score2=accuracy_score(df2['chosen_position'], df2['position'])\n",
    "    print('Accuracy Score Coder 2:',accuracy_score2)\n",
    "    master_list2.append(accuracy_score2)\n",
    "    print( )\n",
    "    precision_score1=precision_score(df1['chosen_position'], df1['position'], average='weighted',zero_division=1)\n",
    "    print('Precision Score Coder 1:',precision_score1)\n",
    "    master_list1.append(precision_score1)\n",
    "    precision_score2=precision_score(df2['chosen_position'], df2['position'], average='weighted',zero_division=1)\n",
    "    print('Precision Score Coder 2:',precision_score2)\n",
    "    master_list2.append(precision_score2)\n",
    "    print( )\n",
    "    recall_score1=recall_score(df1['chosen_position'], df1['position'], average='weighted',zero_division=1)\n",
    "    print('Recall Score Coder 1:',recall_score1)\n",
    "    master_list1.append(recall_score1)\n",
    "    recall_score2=recall_score(df2['chosen_position'], df2['position'], average='weighted',zero_division=1)\n",
    "    print('Recall Score Coder 2:',recall_score2)\n",
    "    master_list2.append(recall_score2)\n",
    "    print( )\n",
    "    \n",
    "    kappa= cohen_kappa_score(df1['chosen_position'],df2['position'])\n",
    "    print('Cohens Kappa for the Coders:',kappa)\n",
    "    return master_list1, master_list2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40a5bf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe and save initial results\n",
    "#list1, list2 = test_evaluation(data1,data2,10,'Stjepan_GloVe_Twitter_bus','Stjepan_GloVe_Twitter_org')\n",
    "#dataframe = pd.DataFrame([list1],columns=[\"Name\",\"F1_Score\",\"Accuracy_Score\",\"Precision_Score\",\"Recall_Score\"])\n",
    "#dataframe.loc[len(dataframe)] = list2\n",
    "#dataframe.to_csv(\"/Users/stjepankusenic/POLAR_WEBE/data/processed/eval_results_individual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6a48d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>F1_Score</th>\n",
       "      <th>Accuracy_Score</th>\n",
       "      <th>Precision_Score</th>\n",
       "      <th>Recall_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stjepan_GloVe_Twitter_bus</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stjepan_GloVe_Twitter_org</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stjepan_GloVe_Wiki_bus</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stjepan_GloVe_Wiki_org</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stjepan_GoogleNews_bus</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stjepan_GoogleNews_org</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stjepan_Reddit_bus</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Stjepan_Reddit_org</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Renee_GloVe_Twitter_bus</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Renee_GloVe_Twitter_org</td>\n",
       "      <td>0.146667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Renee_GloVe_Wiki_bus</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Renee_GloVe_Wiki_org</td>\n",
       "      <td>0.393333</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Renee_GoogleNews_bus</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Renee_GoogleNews_org</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Renee_Reddit_bus</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Renee_Reddit_org</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Sreehari_GloVe_Twitter_bus</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sreehari_GloVe_Twitter_org</td>\n",
       "      <td>0.306667</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.565000</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Sreehari_GloVe_Wiki_bus</td>\n",
       "      <td>0.445238</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Sreehari_GloVe_Wiki_org</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Sreehari_GoogleNews_bus</td>\n",
       "      <td>0.378571</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Sreehari_GoogleNews_org</td>\n",
       "      <td>0.185714</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Sreehari_Reddit_bus</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Sreehari_Reddit_org</td>\n",
       "      <td>0.152381</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Xhoana_GloVeTwitter_bus</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Xhoana_GloVeTwitter_org</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Xhoana_GloVeWiki_bus</td>\n",
       "      <td>0.486667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Xhoana_GloVeWiki_org</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Xhoana_GoogleNews_bus</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Xhoana_GoogleNews_org</td>\n",
       "      <td>0.271429</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Xhoana_Reddit_bus</td>\n",
       "      <td>0.361905</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Xhoana_Reddit_org</td>\n",
       "      <td>0.291429</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Simran_GloVeTwitter_bus</td>\n",
       "      <td>0.155000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.126667</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Simran_GloVeTwitter_org</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Simran_GloVeWiki_bus</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Simran_GloVeWiki_org</td>\n",
       "      <td>0.388571</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Simran_GoogleNews_bus</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Simran_GoogleNews_org</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Simran_Reddit_bus</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Simran_Reddit_org</td>\n",
       "      <td>0.213333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Name  F1_Score  Accuracy_Score  Precision_Score  \\\n",
       "0    Stjepan_GloVe_Twitter_bus  0.350000             0.4         0.533333   \n",
       "1    Stjepan_GloVe_Twitter_org  0.200000             0.2         0.316667   \n",
       "2       Stjepan_GloVe_Wiki_bus  0.433333             0.5         0.400000   \n",
       "3       Stjepan_GloVe_Wiki_org  0.283333             0.3         0.620000   \n",
       "4       Stjepan_GoogleNews_bus  0.166667             0.2         0.350000   \n",
       "5       Stjepan_GoogleNews_org  0.166667             0.2         0.450000   \n",
       "6           Stjepan_Reddit_bus  0.114286             0.1         0.133333   \n",
       "7           Stjepan_Reddit_org  0.000000             0.0         0.000000   \n",
       "8      Renee_GloVe_Twitter_bus  0.085714             0.1         0.175000   \n",
       "9      Renee_GloVe_Twitter_org  0.146667             0.2         0.116667   \n",
       "10        Renee_GloVe_Wiki_bus  0.283333             0.3         0.400000   \n",
       "11        Renee_GloVe_Wiki_org  0.393333             0.4         0.600000   \n",
       "12        Renee_GoogleNews_bus  0.371429             0.4         0.483333   \n",
       "13        Renee_GoogleNews_org  0.266667             0.2         0.400000   \n",
       "14            Renee_Reddit_bus  0.111111             0.1         0.125000   \n",
       "15            Renee_Reddit_org  0.228571             0.2         0.466667   \n",
       "16  Sreehari_GloVe_Twitter_bus  0.120000             0.1         0.150000   \n",
       "17  Sreehari_GloVe_Twitter_org  0.306667             0.4         0.565000   \n",
       "18     Sreehari_GloVe_Wiki_bus  0.445238             0.4         0.616667   \n",
       "19     Sreehari_GloVe_Wiki_org  0.216667             0.2         0.350000   \n",
       "20     Sreehari_GoogleNews_bus  0.378571             0.4         0.400000   \n",
       "21     Sreehari_GoogleNews_org  0.185714             0.2         0.175000   \n",
       "22         Sreehari_Reddit_bus  0.222222             0.2         0.450000   \n",
       "23         Sreehari_Reddit_org  0.152381             0.2         0.125000   \n",
       "24     Xhoana_GloVeTwitter_bus  0.033333             0.1         0.320000   \n",
       "25     Xhoana_GloVeTwitter_org  0.000000             0.0         0.000000   \n",
       "26        Xhoana_GloVeWiki_bus  0.486667             0.5         0.500000   \n",
       "27        Xhoana_GloVeWiki_org  0.350000             0.3         0.550000   \n",
       "28       Xhoana_GoogleNews_bus  0.325000             0.4         0.480000   \n",
       "29       Xhoana_GoogleNews_org  0.271429             0.3         0.250000   \n",
       "30           Xhoana_Reddit_bus  0.361905             0.3         0.766667   \n",
       "31           Xhoana_Reddit_org  0.291429             0.3         0.300000   \n",
       "32     Simran_GloVeTwitter_bus  0.155000             0.2         0.126667   \n",
       "33     Simran_GloVeTwitter_org  0.280000             0.3         0.266667   \n",
       "34        Simran_GloVeWiki_bus  0.266667             0.2         0.400000   \n",
       "35        Simran_GloVeWiki_org  0.388571             0.3         0.666667   \n",
       "36       Simran_GoogleNews_bus  0.222222             0.2         0.550000   \n",
       "37       Simran_GoogleNews_org  0.200000             0.2         0.733333   \n",
       "38           Simran_Reddit_bus  0.000000             0.0         0.000000   \n",
       "39           Simran_Reddit_org  0.213333             0.2         0.266667   \n",
       "\n",
       "    Recall_Score  \n",
       "0            0.4  \n",
       "1            0.2  \n",
       "2            0.5  \n",
       "3            0.3  \n",
       "4            0.2  \n",
       "5            0.2  \n",
       "6            0.1  \n",
       "7            0.0  \n",
       "8            0.1  \n",
       "9            0.2  \n",
       "10           0.3  \n",
       "11           0.4  \n",
       "12           0.4  \n",
       "13           0.2  \n",
       "14           0.1  \n",
       "15           0.2  \n",
       "16           0.1  \n",
       "17           0.4  \n",
       "18           0.4  \n",
       "19           0.2  \n",
       "20           0.4  \n",
       "21           0.2  \n",
       "22           0.2  \n",
       "23           0.2  \n",
       "24           0.1  \n",
       "25           0.0  \n",
       "26           0.5  \n",
       "27           0.3  \n",
       "28           0.4  \n",
       "29           0.3  \n",
       "30           0.3  \n",
       "31           0.3  \n",
       "32           0.2  \n",
       "33           0.3  \n",
       "34           0.2  \n",
       "35           0.3  \n",
       "36           0.2  \n",
       "37           0.2  \n",
       "38           0.0  \n",
       "39           0.2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#save further results into the same datadrame\n",
    "dataframe= pd.read_csv('../data/processed/eval_results_individual')\n",
    "dataframe=dataframe.drop(columns=['Unnamed: 0'])\n",
    "#list1, list2 = test_evaluation(data1,data2,10,'Simran_Reddit_bus','Simran_Reddit_org')\n",
    "#dataframe.loc[len(dataframe)] = list1\n",
    "#dataframe.loc[len(dataframe)] = list2\n",
    "#look at the results\n",
    "display(dataframe)\n",
    "#dataframe.to_csv('/Users/stjepankusenic/POLAR_WEBE/data/processed/eval_results_individual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1399ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coder-combination</th>\n",
       "      <th>Kappa-bus</th>\n",
       "      <th>Kappa-org</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stjepan-Renee</td>\n",
       "      <td>0.367089</td>\n",
       "      <td>-0.282051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stjepan-Simran</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.047619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stjepan-Sreehari</td>\n",
       "      <td>0.135802</td>\n",
       "      <td>0.047619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stjepan-Xhoana</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>-0.139241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Renee-Simran</td>\n",
       "      <td>-0.139241</td>\n",
       "      <td>0.230769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Renee-Sreehari</td>\n",
       "      <td>0.135802</td>\n",
       "      <td>0.047619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Renee-Xhoana</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.084337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Simran-Sreehari</td>\n",
       "      <td>-0.315789</td>\n",
       "      <td>0.102564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Simran-Xhoana</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.146341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sreehari-Xhoana</td>\n",
       "      <td>-0.139241</td>\n",
       "      <td>-0.125000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Coder-combination  Kappa-bus  Kappa-org\n",
       "0     Stjepan-Renee   0.367089  -0.282051\n",
       "1    Stjepan-Simran   0.090909   0.047619\n",
       "2  Stjepan-Sreehari   0.135802   0.047619\n",
       "3    Stjepan-Xhoana   0.230769  -0.139241\n",
       "4      Renee-Simran  -0.139241   0.230769\n",
       "5    Renee-Sreehari   0.135802   0.047619\n",
       "6      Renee-Xhoana   0.000000  -0.084337\n",
       "7   Simran-Sreehari  -0.315789   0.102564\n",
       "8     Simran-Xhoana   0.090909   0.146341\n",
       "9   Sreehari-Xhoana  -0.139241  -0.125000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#look at the results for the inter-annotator test\n",
    "display(pd.read_excel(r'../data/processed/eval-results-intercoder-glovewiki.xlsx'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}