{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "DJBD4VmIhLzq"
   },
   "outputs": [],
   "source": [
    "from operator import index\n",
    "from pandas.core.frame import DataFrame\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from random import shuffle\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import plotly\n",
    "import colorlover as cl\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FA5W9e8JCdGv"
   },
   "source": [
    "**Choose the required options from the below cell and the results can been seen at the end of the notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4W2s3wmShL43",
    "outputId": "66f12e0d-b684-4d94-9381-b7e35df8cea1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please choose any of the Pretrained Model\n",
      "1. Glove Wiki\n",
      "2. Google News\n",
      "Enter the Pretrained Model Number: 2\n",
      "\n",
      "Please choose any to see performance of Polar embedding --> Hofstede\n",
      "1. Average Performance of the model over all the Hofstede's dimension\n",
      "2. Performance of the model over a single Hofstede Dimension\n",
      "Enter the Option Number: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Please choose any of the Pretrained Model\")\n",
    "print(\"1. Glove Wiki\")\n",
    "print(\"2. Google News\")\n",
    "pretrained_model = input(\"Enter the Pretrained Model Number: \")\n",
    "\n",
    "print(\"\\nPlease choose any to see performance of Polar embedding --> Hofstede\")\n",
    "print(\"1. Average Performance of the model over all the Hofstede's dimension\")\n",
    "print(\"2. Performance of the model over a single Hofstede Dimension\")\n",
    "polar_evaluation = input(\"Enter the Option Number: \")\n",
    "\n",
    "if polar_evaluation in \"2. Individual Performance of the model\":\n",
    "  \n",
    "  print(\"\\nPlease choose any of the Hofstede dimension\")\n",
    "  print(\"1. Power Distance\")\n",
    "  print(\"2. Individualism vs Collectivism\")\n",
    "  print(\"3. Masculinity vs Femininity\")\n",
    "  print(\"4. Long Term vs Short Term Orientation\")\n",
    "  print(\"5. Indulgence vs Restraint\")\n",
    "  print(\"6. Uncertainty Avoidance\\n\")\n",
    "\n",
    "  Hofstede_dimensions = input(\"Enter the Hofstede Dimension Number: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "qVnThjRdeL8s"
   },
   "outputs": [],
   "source": [
    "avgrank_random_list=[]\n",
    "avgrank_nearest_random_list=[]\n",
    "avgrank_human_list=[]\n",
    "avgrank_nearest_human_list=[]\n",
    "\n",
    "avgscore_random_list = []\n",
    "avgscore_nearest_random_list = []\n",
    "avgscore_human_list = []\n",
    "avgscore_nearest_human_list = []\n",
    "\n",
    "MAE_random = []\n",
    "correlation_rank_random = []\n",
    "rmse_random = []\n",
    "\n",
    "MAE_human = []\n",
    "correlation_rank_human = []\n",
    "rmse_human = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Gmi9CgYjcmNO"
   },
   "outputs": [],
   "source": [
    "avg_corr_rank_random_list = []\n",
    "avg_corr_rank_nearest_random_list = []\n",
    "avg_corr_rank_human_list = []\n",
    "avg_corr_rank_nearest_human_list = []\n",
    "\n",
    "avg_corr_score_random_list = []\n",
    "avg_corr_score_nearest_random_list = []\n",
    "avg_corr_score_human_list = []\n",
    "avg_corr_score_nearest_human_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "HnaJiJirco3F"
   },
   "outputs": [],
   "source": [
    "def list_avg(avg_list):\n",
    "  sum = 0\n",
    "  for i in avg_list:\n",
    "    sum = sum + i\n",
    "  return sum/len(avg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "levbHQzQhGnb"
   },
   "outputs": [],
   "source": [
    "def polar_list(list):\n",
    "  \n",
    "  right_polar_list = []\n",
    "  left_polar_list = []\n",
    "  for i in range(0,len(list)):\n",
    "    \n",
    "    left_polar_list.append(list[i][0].replace(\"-\",\"_\"))\n",
    "    right_polar_list.append(list[i][1].replace(\"-\",\"_\"))\n",
    "\n",
    "  return left_polar_list,right_polar_list\n",
    "\n",
    "\n",
    "def alphabetical_list_creation(list):\n",
    "  new_list = []\n",
    "  \n",
    "  for i in range(0,len(list)):\n",
    "    index_0 = list[i][0].replace(\"-\",\"_\")\n",
    "    index_1 = list[i][1].replace(\"-\",\"_\")\n",
    "    \n",
    "    if index_0 < index_1:\n",
    "      val = index_0+\"-\"+index_1\n",
    "      new_list.append(val)\n",
    "      \n",
    "    else:\n",
    "      val = index_1+\"-\"+index_0\n",
    "      new_list.append(val)\n",
    "      \n",
    "  return new_list\n",
    "\n",
    "def company_count(company_df,input_list,polar_embedding):  \n",
    "\n",
    "  # we then find the number of companies grouped on the basis of location\n",
    "  for i in input_list:       \n",
    "    j = i.replace(\"-\",\"\")    \n",
    "    j = j.replace(\"_\",\"-\")\n",
    "    \n",
    "    subset_df2 = polar_embedding[polar_embedding[j] < 0]\n",
    "    company_inclined_to_left_polar_df1 = subset_df2['Location'].value_counts()\n",
    "    left_polar = i.split(\"-\")[0]\n",
    "    \n",
    "    company_inclined_to_left_polar_df1 = pd.DataFrame({'Country':company_inclined_to_left_polar_df1.index, left_polar :company_inclined_to_left_polar_df1.values})\n",
    "    company_df=pd.merge(company_df, company_inclined_to_left_polar_df1, how='left',on='Country')    \n",
    "    company_df[left_polar] = round( company_df[left_polar] / company_df.iloc[:,1] * 100)\n",
    "\n",
    "    subset_df1 = polar_embedding[polar_embedding[j] > 0]\n",
    "    company_inclined_to_right_polar_df1 = subset_df1['Location'].value_counts()\n",
    "    right_polar = i.split(\"-\")[1]\n",
    "    \n",
    "    company_inclined_to_right_polar_df1 = pd.DataFrame({'Country':company_inclined_to_right_polar_df1.index, right_polar :company_inclined_to_right_polar_df1.values})\n",
    "    company_df=pd.merge(company_df, company_inclined_to_right_polar_df1, how='left',on='Country')    \n",
    "    company_df[right_polar] = round( company_df[right_polar] / company_df.iloc[:,1] * 100)\n",
    "\n",
    "\n",
    "  company_df = company_df.fillna(0)\n",
    "\n",
    "  # We are considering only the countries if the numberof companies in the country is over 3\n",
    "  company_df = company_df[company_df['Total Count'] > 3]\n",
    "\n",
    "  return company_df\n",
    "\n",
    "\n",
    "def polar_ranking(polar_list,total_score,ranking,company_df):\n",
    "  total_sum=0\n",
    "  total_sum_list=[]\n",
    "  polar_ranking_list = []\n",
    "  polar_index=0\n",
    "  for index,row in company_df.iterrows():  \n",
    "    \n",
    "    for i in polar_list:\n",
    "      \n",
    "      total_sum = total_sum + (row[i])\n",
    "    #print(company_df.iloc[index,2:])  \n",
    "    total_sum_list.append(total_sum/len(polar_list))\n",
    "    polar_ranking_list.append(index+1)\n",
    "    total_sum = 0\n",
    "\n",
    "  company_df[total_score] = total_sum_list\n",
    "  company_df= company_df.sort_values(by=[total_score],ascending=False)\n",
    "  company_df[ranking] = polar_ranking_list\n",
    "\n",
    "  return company_df\n",
    "\n",
    "def normalize(x):\n",
    "  return (x-np.min(x)) / (np.max(x) - np.min(x))\n",
    "\n",
    "# Mean absolute error of the score\n",
    "def mean_absolute_error_score(merged_df,dimension):\n",
    "  MAE_of_Score = []\n",
    "  MAE_of_Score.append(mean_absolute_error(merged_df[dimension], merged_df[\"Total Score Random\"]))\n",
    "  MAE_of_Score.append(mean_absolute_error(merged_df[dimension], merged_df[\"Total Score Nearest Random\"]))\n",
    "  MAE_of_Score.append(mean_absolute_error(merged_df[dimension], merged_df[\"Total Score Human\"]))\n",
    "  MAE_of_Score.append(mean_absolute_error(merged_df[dimension], merged_df[\"Total Score Nearest Human\"]))\n",
    "  return MAE_of_Score\n",
    "\n",
    "# Mean absolute error of the rank\n",
    "def mean_absolute_error_rank(merged_df,dimension_ranking):\n",
    "  MAE = []\n",
    "  MAE.append(mean_absolute_error(merged_df[dimension_ranking], merged_df[\"Polar Rank R\"]))\n",
    "  MAE.append(mean_absolute_error(merged_df[dimension_ranking], merged_df[\"Polar Rank Nearest R\"]))\n",
    "  MAE.append(mean_absolute_error(merged_df[dimension_ranking], merged_df[\"Polar Rank H\"]))\n",
    "  MAE.append(mean_absolute_error(merged_df[dimension_ranking], merged_df[\"Polar Rank Nearest H\"]))\n",
    "  return MAE\n",
    "\n",
    "# Root Mean squared error of the score\n",
    "def root_mean_squared_error_score(merged_df,dimension):\n",
    "  RMSE_of_Score = []\n",
    "  RMSE_of_Score.append(np.sqrt(mean_squared_error(merged_df[dimension], merged_df[\"Total Score Random\"])))\n",
    "  RMSE_of_Score.append(np.sqrt(mean_squared_error(merged_df[dimension], merged_df[\"Total Score Nearest Random\"])))\n",
    "  RMSE_of_Score.append(np.sqrt(mean_squared_error(merged_df[dimension], merged_df[\"Total Score Human\"])))\n",
    "  RMSE_of_Score.append(np.sqrt(mean_squared_error(merged_df[dimension], merged_df[\"Total Score Nearest Human\"])))\n",
    "  return RMSE_of_Score\n",
    "\n",
    "# Root Mean squarred error of the rank\n",
    "def root_mean_squared_error_rank(merged_df,dimension_ranking):\n",
    "  RMSE = []\n",
    "  RMSE.append(np.sqrt(mean_squared_error(merged_df[dimension_ranking], merged_df[\"Polar Rank R\"])))\n",
    "  RMSE.append(np.sqrt(mean_squared_error(merged_df[dimension_ranking], merged_df[\"Polar Rank Nearest R\"])))\n",
    "  RMSE.append(np.sqrt(mean_squared_error(merged_df[dimension_ranking], merged_df[\"Polar Rank H\"])))\n",
    "  RMSE.append(np.sqrt(mean_squared_error(merged_df[dimension_ranking], merged_df[\"Polar Rank Nearest H\"])))\n",
    "  return RMSE\n",
    "\n",
    "# Normalized Root Mean squarred error of the score\n",
    "def normalized_root_mean_squared_error_score(merged_df,dimension):\n",
    "  N_RMSE = []\n",
    "  N_RMSE.append(np.sqrt(mean_squared_error(normalize(merged_df[dimension].astype(int)), normalize(merged_df[\"Total Score Random\"]))))\n",
    "  N_RMSE.append(np.sqrt(mean_squared_error(normalize(merged_df[dimension].astype(int)), normalize(merged_df[\"Total Score Nearest Random\"]))))\n",
    "  N_RMSE.append(np.sqrt(mean_squared_error(normalize(merged_df[dimension].astype(int)), normalize(merged_df[\"Total Score Human\"]))))\n",
    "  N_RMSE.append(np.sqrt(mean_squared_error(normalize(merged_df[dimension].astype(int)), normalize(merged_df[\"Total Score Nearest Human\"]))))\n",
    "  return N_RMSE\n",
    "\n",
    "def correlation_calc(merged_df,dimension_ranking):\n",
    "  correlation = []\n",
    "  correlation.append(merged_df[\"Polar Rank R\"].corr(merged_df[dimension_ranking]))\n",
    "  correlation.append(merged_df[\"Polar Rank Nearest R\"].corr(merged_df[dimension_ranking]))\n",
    "  correlation.append(merged_df[\"Polar Rank H\"].corr(merged_df[dimension_ranking]))\n",
    "  correlation.append(merged_df[\"Polar Rank Nearest H\"].corr(merged_df[dimension_ranking]))\n",
    "  return correlation\n",
    "\n",
    "def correlation_calc_score(merged_df,dimension):\n",
    "  correlation = []\n",
    "  correlation.append(merged_df[\"Total Score Random\"].corr(merged_df[dimension].astype(int)))\n",
    "  correlation.append(merged_df[\"Total Score Nearest Random\"].corr(merged_df[dimension].astype(int)))\n",
    "  correlation.append(merged_df[\"Total Score Human\"].corr(merged_df[dimension].astype(int)))\n",
    "  correlation.append(merged_df[\"Total Score Nearest Human\"].corr(merged_df[dimension].astype(int)))\n",
    "  return correlation  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3NzhzgzziuDt"
   },
   "source": [
    "**Below cell choose the polar embedding and lists for respective Pretrained model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "nBxDImlwhpyx"
   },
   "outputs": [],
   "source": [
    "if pretrained_model in \"1. Glove Wiki\": \n",
    "\n",
    "  new_df = pd.read_csv('../data/processed/120_dimension_polar_embedding.csv')\n",
    "\n",
    "  # Power Distance (High Power Distance, Low Power Distance)\n",
    "  list_powerdistance_random =[('make', 'break'), ('cameraman', 'playwright'), ('mystical', 'factual'), ('promotional', 'defamation'), ('iconic', 'unknown')]\n",
    "  nearest_random_list_powerdistance =[('making', 'breaking'), ('cameramen', 'dramatist'), ('magical', 'inaccuracies'), ('promo', 'libel'), ('recognizable', 'undetermined')]\n",
    "  list_powerdistance =[('hierarchical','non-hierarchical'),('superior','equal'),('leader','subordinate'),('inequality','equality'),('autocrat','democrat')]\n",
    "  nearest_human_list_powerdistance = [('hierarchy', 'consensus-based'), ('inferior', 'equalitys'), ('leaders', 'subordinates'), ('inequalities', 'equals'), ('autocratic', 'senator')]\n",
    "\n",
    "  # Individualism (Individualism, Collectivism)\n",
    "  list_individualism_random = [('lop', 'secure'), ('shah', 'poor'), ('pneumatic', 'solid'), ('interpret', 'misinterpret'), ('confer', 'refuse')]\n",
    "  nearest_random_list_individualism= [('buri', 'securing'), ('ahmad', 'poorer'), ('hydraulic', 'consistent'), ('interpreting', 'misunderstand'), ('conferring', 'refusing')]\n",
    "  list_individualism = [('individuality','community'),('self-interest','harmony'),('tasks','relationships'),('individual','groups'),('universalism','particularism')]\n",
    "  nearest_human_list_individualism = [('originality', 'communities'), ('selfishness', 'harmonious'), ('task', 'relationship'), ('individuals', 'group'), ('mangxamba', 'unitarianism')]\n",
    "\n",
    "  # Masculinity\n",
    "  list_masculinity_random = [('try', 'abstain'), ('fatalistic', 'freewill'), ('knowledgeable', 'uninformed'), ('confine', 'free'), ('fan', 'warm')]\n",
    "  nearest_random_list_masculinity = [('trying', 'abstaining'), ('nonchalant', 'gmv'), ('knowledgable', 'misinformed'), ('confining', 'freedom'), ('fans', 'cool')]\n",
    "  list_masculinity = [('achievement', 'support'),('competitive', 'caring'),('assertive', 'submissive'),('ambitious', 'unambitious'),('sucess','cooperation')]\n",
    "  nearest_human_list_masculinity = [('achievements', 'supported'), ('competition', 'loving'), ('forceful', 'subservient'), ('undertaking', 'unathletic'), ('ufauthor', 'bilateral')]\n",
    "\n",
    "  # long term Orientation\n",
    "  list_longterm_random = [('innovator', 'follower'), ('sensory', 'numb'), ('hedge', 'squander'), ('arachnid', 'serpent'), ('disclose', 'secrete')]\n",
    "  nearest_random_list_longterm = [('visionary', 'disciple'), ('auditory', 'numbed'), ('fund', 'squandering'), ('itsy', 'serpents'), ('disclosing', 'secreted')]\n",
    "  list_longterm = [('pragmatic','normative'),('progress','preserve'),('adapt','conserve'),('developing','stable'),('advance','retain')]\n",
    "  nearest_human_list_longterm = [('pragmatism', 'conceptions'), ('efforts', 'preserving'), ('adapting', 'conserving'), ('develop', 'stability'), ('advancing', 'retained')]\n",
    "\n",
    "  # Indulgence\n",
    "  list_indulgence_random = [('diagnose', 'sicken'), ('intercourse', 'disconnection'), ('sensory', 'sensorial'), ('emasculate', 'strengthen'), ('metropolitan', 'rural')]\n",
    "  nearest_random_list_indulgence = [('diagnosing', 'sickens'), ('sexual', 'disconnect'), ('auditory', 'skorokhod'), ('disempower', 'strengthening'), ('metro', 'urban')]\n",
    "  list_indulgence = [('fulfillment','restriction'),('satisfaction','limitation'),('liberty','moderation'),('expand','direct'),('freedom','regulation')]\n",
    "  nearest_human_list_indulgence = [('fulfilment', 'restrictions'), ('satisfied', 'limitations'), ('fredom', 'restraint'), ('expanding', 'indirect'), ('freedoms', 'regulations')]\n",
    "\n",
    "  # Unceratinity Avoidance\n",
    "  list_uncertainity_avoidance_random = [('stretcher', 'compressor'), ('amalgamate', 'separate'), ('caretaker', 'assailant'), ('taker', 'violator'), ('contaminate', 'sterilize')]\n",
    "  nearest_random_list_uncertainity_avoidance = [('stretchers', 'compressors'), ('amalgamating', 'separately'), ('interim', 'assailants'), ('takers', 'violators'), ('contaminating', 'sterilized')]\n",
    "  list_uncertainity_avoidance = [('clarity','complexity'),('clear','ambiguous'),('certain','uncertain'),('uniformity','diversity'),('agreement','variation')]\n",
    "  nearest_human_list_uncertainity_avoidance = [('simplicity', 'complexities'), ('yet', 'vague'), ('particular', 'unclear'), ('homogeneity', 'diverse'), ('agreements', 'variations')]\n",
    "\n",
    "else:\n",
    "\n",
    "  new_df = pd.read_csv('../data/processed/polar_embedding_gnews.csv')\n",
    "  new_df['Unnamed: 0'] = new_df['Unnamed: 0'].str.lower()\n",
    "  new_df['Unnamed: 0'] = new_df['Unnamed: 0'].str.replace(\"_\",\"\")\n",
    "\n",
    "  # Power Distance (High Power Distance, Low Power Distance)\n",
    "  list_powerdistance_random =[('make', 'break'), ('cameraman', 'playwright'), ('mystical', 'factual'), ('promotional', 'defamation'), ('iconic', 'unknown')]\n",
    "  nearest_random_list_powerdistance = [('making', 'breaks'), ('camerman', 'dramatist'), ('mystic', 'facts'), ('Promotional', 'libel'), ('Iconic', 'unkown')]\n",
    "  list_powerdistance =[('hierarchical','nonhierarchical'),('superior','equal'),('leader','subordinate'),('inequality','equality'),('autocrat','democrat')]\n",
    "  nearest_human_list_powerdistance = [('hierarchal', 'rigidhierarchical'), ('inferior', 'Equal'), ('leadership', 'subordinates'), ('inequalities', 'genderequality'), ('despot', 'democrats')]\n",
    "\n",
    "  # Individualism (Individualism, Collectivism)\n",
    "  list_individualism_random = [('lop', 'secure'), ('shah', 'poor'), ('pneumatic', 'solid'), ('interpret', 'misinterpret'), ('confer', 'refuse')]\n",
    "  nearest_random_list_individualism = [('lopped', 'securing'), ('Pahlavi', 'poorer'), ('hydraulic', 'strong'), ('interpreting', 'misunderstand'), ('conferred', 'refusing')]\n",
    "  list_individualism = [('individuality','community'),('egotism','harmony'),('tasks','relationships'),('individual','groups'),('particularism','universalism')]\n",
    "  nearest_human_list_individualism = [('individualism', 'communities'), ('narcissism', 'harmonious'), ('mundanetasks', 'relationship'), ('individually', 'Groups'), ('exclusivism', 'universalist')]\n",
    "\n",
    "  # Masculinity\n",
    "  list_masculinity_random = [('try', 'abstain'), ('fatalistic', 'freewill'), ('knowledgeable', 'uninformed'), ('confine', 'free'), ('fan', 'warm')]\n",
    "  nearest_random_list_masculinity = [('trying', 'abstaining'), ('fatalist', 'eternaldestiny'), ('knowledgable', 'ignorant'), ('confining', 'Free'), ('fans', 'Warm')]\n",
    "  list_masculinity = [('achievement', 'support'),('competitive', 'caring'),('assertive', 'submissive'),('ambitious', 'unambitious'),('sucess','cooperation')]\n",
    "  nearest_human_list_masculinity = [('acheivement', 'supporting'), ('competitve', 'compassionate'), ('assertiveness', 'subservient'), ('Ambitious', 'unimaginative'), ('success', 'bilateralcooperation')]\n",
    "\n",
    "  # long term Orientation\n",
    "  list_longterm_random = [('innovator', 'follower'), ('sensory', 'numb'), ('hedge', 'squander'), ('arachnid', 'serpent'), ('disclose', 'secrete')]\n",
    "  nearest_random_list_longterm = [('pioneer', 'devotee'), ('auditory', 'numbed'), ('hedges', 'squandered'), ('spider', 'serpents'), ('divulge', 'secretes')]\n",
    "  list_longterm = [('pragmatic','normative'),('progress','preserve'),('adapt','conserve'),('developing','stable'),('advance','retain')]\n",
    "  nearest_human_list_longterm = [('pragmatism', 'deontological'), ('progess', 'preserving'), ('adapting', 'conserving'), ('develop', 'stabile'), ('advancing', 'retaining')]\n",
    "\n",
    "  # Indulgence\n",
    "  list_indulgence_random = [('diagnose', 'sicken'), ('intercourse', 'disconnection'), ('sensorys', 'sensorial'), ('emasculate', 'strengthen'), ('metropolitan', 'rural')]\n",
    "  nearest_random_list_indulgence = [('accuratelydiagnose', 'sickens'), ('sexualintercourse', 'disconnections'), ('auditory', 'sensory'), ('eviscerate', 'strengthening'), ('metro', 'Rural')]\n",
    "  list_indulgence = [('fulfillment','restriction'),('satisfaction','limitation'),('liberty','moderation'),('expand','direct'),('freedom','regulation')]\n",
    "  nearest_human_list_indulgence = [('fulfillments', 'restrictions'), ('Satisfaction', 'limitations'), ('fredom', 'Moderation'), ('broaden', 'indirect'), ('freedoms', 'regulations')]\n",
    "\n",
    "  # Unceratinity Avoidance\n",
    "  list_uncertainity_avoidance_random = [('stretcher', 'compressor'), ('amalgamate', 'separate'), ('caretaker', 'assailant'), ('taker', 'violator'), ('contaminate', 'sterilize')]\n",
    "  nearest_random_list_uncertainity_avoidance = [('stretchers', 'compressors'), ('merge', 'seperate'), ('Caretaker', 'assailants'), ('takers', 'violators'), ('contaminating', 'sterilized')]\n",
    "  list_uncertainity_avoidance = [('clarity','complexity'),('clear','ambiguous'),('certain','uncertain'),('uniformity','diversity'),('agreement','variation')]\n",
    "  nearest_human_list_uncertainity_avoidance = [('coherence', 'complexities'), ('crystalclear', 'vague'), ('these', 'unsure'), ('homogeneity', 'culturaldiversity'), ('agreements', 'variations')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZrPBwG4how8P"
   },
   "source": [
    "Below cell loads all the required CSV files like the Fortune 500 comapnies and Hofstede's cultural dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "5StW0UkNowZ5"
   },
   "outputs": [],
   "source": [
    "# Loads the Fortune 500 companies and its locations\n",
    "fortune_500_company = pd.read_csv('../data/raw/Fortune_Global_500_companies.csv',encoding= 'unicode_escape')\n",
    "fortune_500_company['Company'] = fortune_500_company['Company'].str.lower()\n",
    "fortune_500_company['Company'] = fortune_500_company['Company'].str.replace(\" \", \"\")\n",
    "\n",
    "# We are mergin inorder to get the location of the company\n",
    "polar_embedding = pd.merge(fortune_500_company, new_df, how=\"right\", left_on=\"Company\", right_on=\"Unnamed: 0\")\n",
    "\n",
    "polar_embedding = polar_embedding.drop(['Rank'], axis=1)  # This will drop the column Rank\n",
    "polar_embedding = polar_embedding.drop(['Unnamed: 0'], axis=1)  # This will drop the column Rank\n",
    "\n",
    "# This will find the total number of companies in our data frame based on Location\n",
    "total_company_list_based_on_loc = polar_embedding['Location'].value_counts()\n",
    "total_company_count_df = pd.DataFrame({'Country': total_company_list_based_on_loc.index, 'Total Count': total_company_list_based_on_loc.values})\n",
    "\n",
    "# This will load the Hofstede 6 Dimension dataset\n",
    "hofstede_df = pd.read_csv(\"../data/raw/Hofstede_6_dimensions.csv\",sep=\";\")\n",
    "hofstede_df=hofstede_df[hofstede_df.iloc[:,:]!=\"#NULL!\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 856
    },
    "id": "4DKMnX0Ccqf0",
    "outputId": "583d7c43-00a9-4e1f-b805-ec95e394bf3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random list - Average Mean Absolute Error of Rank:  4.822222222222223\n",
      "Nearest Random list - Average Mean Absolute Error of Rank:  5.088888888888889\n",
      "Human Made list - Average Mean Absolute Error of Rank:  4.9111111111111105\n",
      "Nearest Human Made list - Average Mean Absolute Error of Rank:  4.6000000000000005\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Random list - Average RMSE of Score:  24.90156017344138\n",
      "Nearest Random list - Average RMSE of Score:  24.510050170651397\n",
      "Human Made list - Average RMSE of Score:  22.030762521025338\n",
      "Nearest Human Made list - Average RMSE of Score:  21.690264527170488\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Random list - Average Correlation of Rank:  0.03035714285714285\n",
      "Nearest Random list - Average Correlation of Rank:  0.028571428571428564\n",
      "Human Made list - Average Correlation of Rank:  0.07738095238095237\n",
      "Nearest Human Made list - Average Correlation of Rank:  0.13809523809523808\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Random list - Average Correlation of Score:  0.049201442796198834\n",
      "Nearest Random list - Average Correlation of Score:  0.0667471535140323\n",
      "Human Made list - Average Correlation of Score:  0.09861868723291219\n",
      "Nearest Human Made list - Average Correlation of Score:  0.12515903190549008\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Below table displays the Average error between the Random List and Nearest Random list\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average MAE of Rank</th>\n",
       "      <th>Average Correlation</th>\n",
       "      <th>Average RMSE of Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random List</th>\n",
       "      <td>5.244444</td>\n",
       "      <td>-0.077381</td>\n",
       "      <td>10.960524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Average MAE of Rank  Average Correlation  Average RMSE of Score\n",
       "Random List             5.244444            -0.077381              10.960524"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Below table displays the Average error between the Human List and Nearest Human list\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average MAE of Rank</th>\n",
       "      <th>Average Correlation</th>\n",
       "      <th>Average RMSE of Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Human List</th>\n",
       "      <td>4.866667</td>\n",
       "      <td>0.025595</td>\n",
       "      <td>11.27548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Average MAE of Rank  Average Correlation  Average RMSE of Score\n",
       "Human List             4.866667             0.025595               11.27548"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hofstede_dimension_list = []\n",
    "if polar_evaluation in \"1. Average Performance of the model over all the Hofstede's dimension\" :\n",
    "  hofstede_dimension_list = [\"Power Distance\", \"Individualism vs Collectivism\", \"Masculinity vs Femininity\", \"Long Term vs Short Term Orientation\", \"Indulgence vs Restraint\", \"Uncertainty Avoidance\" ]\n",
    "else:\n",
    "  hofstede_dimension_list.append(Hofstede_dimensions)\n",
    "\n",
    "\n",
    "for i in hofstede_dimension_list:  \n",
    "\n",
    "  if i in '1. Power Distance' :\n",
    "    Hofstede_dimensions = \"Power Distance\"\n",
    "    dim_index=\"Power distance index\"\n",
    "    dimension_ranking=\"Power distance Ranking\"\n",
    "    \n",
    "    left_polar_list_random,right_polar_list_random = polar_list(list_powerdistance_random)\n",
    "    left_polar_list_nearest_random,right_polar_list_nearest_random = polar_list(nearest_random_list_powerdistance)\n",
    "    left_polar_list_human,right_polar_list_human = polar_list(list_powerdistance)\n",
    "    left_polar_list_nearest_human,right_polar_list_nearest_human = polar_list(nearest_human_list_powerdistance)\n",
    "\n",
    "\n",
    "    input_list_random = alphabetical_list_creation(list_powerdistance_random)\n",
    "    input_list_nearest_random = alphabetical_list_creation(nearest_random_list_powerdistance)\n",
    "    input_list_human = alphabetical_list_creation(list_powerdistance)\n",
    "    input_list_nearest_human = alphabetical_list_creation(nearest_human_list_powerdistance)    \n",
    "\n",
    "  elif i in '2. Individualism vs Collectivism':\n",
    "    Hofstede_dimensions = \"Individualism vs Collectivism\"\n",
    "    dim_index=\"Individualism index\"\n",
    "    dimension_ranking=\"Individualism Ranking\"\n",
    "      \n",
    "\n",
    "    left_polar_list_random,right_polar_list_random = polar_list(list_individualism_random)\n",
    "    left_polar_list_nearest_random,right_polar_list_nearest_random = polar_list(nearest_random_list_individualism)\n",
    "    left_polar_list_human,right_polar_list_human = polar_list(list_individualism)\n",
    "    left_polar_list_nearest_human,right_polar_list_nearest_human = polar_list(nearest_human_list_individualism)\n",
    "\n",
    "\n",
    "    input_list_random = alphabetical_list_creation(list_individualism_random)\n",
    "    input_list_nearest_random = alphabetical_list_creation(nearest_random_list_individualism)\n",
    "    input_list_human = alphabetical_list_creation(list_individualism)\n",
    "    input_list_nearest_human = alphabetical_list_creation(nearest_human_list_individualism)\n",
    "\n",
    "  elif i in '3. Masculinity vs Femininity':\n",
    "    Hofstede_dimensions = \"Masculinity vs Femininity\"\n",
    "    dim_index=\"Masculinity index\"\n",
    "    dimension_ranking=\"Masculinity Ranking\"\n",
    "\n",
    "    \n",
    "    left_polar_list_random,right_polar_list_random = polar_list(list_masculinity_random)\n",
    "    left_polar_list_nearest_random,right_polar_list_nearest_random = polar_list(nearest_random_list_masculinity)\n",
    "    left_polar_list_human,right_polar_list_human = polar_list(list_masculinity)\n",
    "    left_polar_list_nearest_human,right_polar_list_nearest_human = polar_list(nearest_human_list_masculinity)\n",
    "\n",
    "\n",
    "    input_list_random = alphabetical_list_creation(list_masculinity_random)\n",
    "    input_list_nearest_random = alphabetical_list_creation(nearest_random_list_masculinity)\n",
    "    input_list_human = alphabetical_list_creation(list_masculinity)\n",
    "    input_list_nearest_human = alphabetical_list_creation(nearest_human_list_masculinity)\n",
    "      \n",
    "\n",
    "  elif i in '4. Long Term vs Short Term Orientation':\n",
    "    Hofstede_dimensions = \"Long Term vs Short Term Orientation\"\n",
    "    dim_index=\"Long term orientation index\"\n",
    "    dimension_ranking=\"Long term orientation Ranking\"\n",
    "\n",
    "    \n",
    "    left_polar_list_random,right_polar_list_random = polar_list(list_longterm_random)\n",
    "    left_polar_list_nearest_random,right_polar_list_nearest_random = polar_list(nearest_random_list_longterm)\n",
    "    left_polar_list_human,right_polar_list_human = polar_list(list_longterm)\n",
    "    left_polar_list_nearest_human,right_polar_list_nearest_human = polar_list(nearest_human_list_longterm)\n",
    "\n",
    "\n",
    "    input_list_random = alphabetical_list_creation(list_longterm_random)\n",
    "    input_list_nearest_random = alphabetical_list_creation(nearest_random_list_longterm)\n",
    "    input_list_human = alphabetical_list_creation(list_longterm)\n",
    "    input_list_nearest_human = alphabetical_list_creation(nearest_human_list_longterm)\n",
    "      \n",
    "\n",
    "  elif i in '5. Indulgence vs Restraint':\n",
    "    Hofstede_dimensions = \"Indulgence vs Restraint\"\n",
    "    dim_index=\"Indulgence index\"\n",
    "    dimension_ranking=\"Indulgence Ranking\"\n",
    "\n",
    "    \n",
    "    left_polar_list_random,right_polar_list_random = polar_list(list_indulgence_random)\n",
    "    left_polar_list_nearest_random,right_polar_list_nearest_random = polar_list(nearest_random_list_indulgence)\n",
    "    left_polar_list_human,right_polar_list_human = polar_list(list_indulgence)\n",
    "    left_polar_list_nearest_human,right_polar_list_nearest_human = polar_list(nearest_human_list_indulgence)\n",
    "\n",
    "\n",
    "    input_list_random = alphabetical_list_creation(list_indulgence_random)\n",
    "    input_list_nearest_random = alphabetical_list_creation(nearest_random_list_indulgence)\n",
    "    input_list_human = alphabetical_list_creation(list_indulgence)\n",
    "    input_list_nearest_human = alphabetical_list_creation(nearest_human_list_indulgence)\n",
    "      \n",
    "\n",
    "  elif i in '6. Uncertainty Avoidance':\n",
    "    Hofstede_dimensions = \"Uncertainty Avoidance\"\n",
    "    dim_index=\"Uncertainty avoidance index\"\n",
    "    dimension_ranking=\"Uncertainty avoidance Ranking\"\n",
    "\n",
    "    \n",
    "    left_polar_list_random,right_polar_list_random = polar_list(list_uncertainity_avoidance_random)\n",
    "    left_polar_list_nearest_random,right_polar_list_nearest_random = polar_list(nearest_random_list_uncertainity_avoidance)\n",
    "    left_polar_list_human,right_polar_list_human = polar_list(list_uncertainity_avoidance)\n",
    "    left_polar_list_nearest_human,right_polar_list_nearest_human = polar_list(nearest_human_list_uncertainity_avoidance)\n",
    "\n",
    "\n",
    "    input_list_random = alphabetical_list_creation(list_uncertainity_avoidance_random)\n",
    "    input_list_nearest_random = alphabetical_list_creation(nearest_random_list_uncertainity_avoidance)\n",
    "    input_list_human = alphabetical_list_creation(list_uncertainity_avoidance)\n",
    "    input_list_nearest_human = alphabetical_list_creation(nearest_human_list_uncertainity_avoidance)\n",
    "      \n",
    "\n",
    "  company_df = total_company_count_df.copy()  # This make a copy of data frame\n",
    "\n",
    "  #Below lines will find the number of companies aligned to the respective left word in antonym pair\n",
    "  company_df = company_count(company_df,input_list_random,polar_embedding)\n",
    "  company_df = company_count(company_df,input_list_nearest_random,polar_embedding)\n",
    "  company_df = company_count(company_df,input_list_human,polar_embedding)\n",
    "  company_df = company_count(company_df,input_list_nearest_human,polar_embedding)\n",
    "\n",
    "\n",
    "  #Below lines will find the total score based on the left word and finally give a ranking based on the score\n",
    "  company_df = polar_ranking(left_polar_list_random,\"Total Score Random\",\"Polar Rank R\",company_df)\n",
    "  company_df = polar_ranking(left_polar_list_nearest_random,\"Total Score Nearest Random\",\"Polar Rank Nearest R\",company_df)\n",
    "  company_df = polar_ranking(left_polar_list_human,\"Total Score Human\",\"Polar Rank H\",company_df)\n",
    "  company_df = polar_ranking(left_polar_list_nearest_human,\"Total Score Nearest Human\",\"Polar Rank Nearest H\",company_df)\n",
    "\n",
    "  # Remove unwanted columns from the data frame\n",
    "  length = len(left_polar_list_random) + len(left_polar_list_nearest_random) + len(left_polar_list_human) + len(left_polar_list_nearest_human)\n",
    "  company_df.drop(company_df.iloc[:, 2:2 + (length) * 2], axis=1, inplace=True)\n",
    "\n",
    "  # Removing null values from the data frame\n",
    "  hofstede_df = hofstede_df[hofstede_df.iloc[:, :] != \"#NULL!\"]\n",
    "  hofstede_df.dropna(axis=0)\n",
    "\n",
    "  # This merge the company dataframe and Hofstede dataframe over the common column Country\n",
    "  merged_df = pd.merge(company_df, hofstede_df, how='left', on='Country')\n",
    "\n",
    "  # Below part of code will rank the country based on the Hofstede index\n",
    "  ranking_list = []\n",
    "  for i in range(1, len(merged_df[dim_index]) + 1):\n",
    "      ranking_list.append(i)\n",
    "  merged_df = merged_df.sort_values(by=[dim_index], ascending=False)\n",
    "  merged_df[dimension_ranking] = ranking_list\n",
    "\n",
    "  \n",
    "  # This will compute the mean absolute error between the Hofstede rank and the ranks we got based on the score for our lists\n",
    "  MAE = mean_absolute_error_rank(merged_df,dimension_ranking)\n",
    "  # This will compute the mean absolute error between the Hofstede score and the score for our lists\n",
    "  MAE_of_Score = mean_absolute_error_score(merged_df,dim_index)\n",
    "  # This will compute the correlation between the Hofstede rank and the ranks we got based on the score for our lists\n",
    "  correlation_rank = correlation_calc(merged_df,dimension_ranking)\n",
    "  # This will compute the correlation between the Hofstede score and the score for our lists\n",
    "  correlation_score = correlation_calc_score(merged_df,dim_index)\n",
    "  # This will compute the rmse between the Hofstede score and the score for our lists    \n",
    "  rmse = root_mean_squared_error_score(merged_df,dim_index)\n",
    "\n",
    "  # The below code creates a data frame with the results\n",
    "  eval_data = {\"Mean Absolute Error of Rank\" : MAE,\n",
    "                \"Correlation between rank\" : correlation_rank,\n",
    "              \"RMSE of Score\" : rmse,\n",
    "              \"Correlation between score\" : correlation_score,\n",
    "              }\n",
    "\n",
    "  eval_df = pd.DataFrame(eval_data, index =[\"Random List\", \"Nearest Random List\",\"Human Made List\",\"Nearest to Human Made List\"])\n",
    "  \n",
    "  # The below code creates a data frame with the results comparing random list to nearest 5 random list\n",
    "  eval_data_random = {\"Mean Absolute Error of Rank\" : mean_absolute_error(merged_df[\"Polar Rank R\"], merged_df[\"Polar Rank Nearest R\"]),\n",
    "                \"Correlation\" : merged_df[\"Polar Rank R\"].corr(merged_df[\"Polar Rank Nearest R\"]),\n",
    "              \"RMSE of Score\" : np.sqrt(mean_squared_error(merged_df[\"Total Score Random\"], merged_df[\"Total Score Nearest Random\"]))\n",
    "              }\n",
    "  eval_data_random = pd.DataFrame(eval_data_random, index =[\"Random List\"])\n",
    "  \n",
    "              \n",
    "  # The below code creates a data frame with the results comparing human list to nearest 5 human list\n",
    "  eval_data_human = {\"Mean Absolute Error of Rank\" : mean_absolute_error(merged_df[\"Polar Rank H\"], merged_df[\"Polar Rank Nearest H\"]),\n",
    "                \"Correlation\" : merged_df[\"Polar Rank H\"].corr(merged_df[\"Polar Rank Nearest H\"]),\n",
    "              \"RMSE of Score\" : np.sqrt(mean_squared_error(merged_df[\"Total Score Human\"], merged_df[\"Total Score Nearest Human\"]))\n",
    "              }\n",
    "\n",
    "  eval_data_human = pd.DataFrame(eval_data_human, index =[\"Human Made List\"])\n",
    "  \n",
    "  \n",
    "  if polar_evaluation in \"2. Performance of the model over a single Hofstede Dimension\" :\n",
    "    # Below are the correlation plot between the Hofstede rank and ranks of our 4 lists\n",
    "    fig1 = plt.figure(figsize = (10,7))\n",
    "    plt.subplot(2, 2, 1)\n",
    "    sns.regplot(x=merged_df[dimension_ranking], y=merged_df[\"Polar Rank R\"])\n",
    "    plt.xlabel('Ranking based on ' + str(Hofstede_dimensions))\n",
    "    plt.ylabel('Polar Rank based on Random list')\n",
    "    plt.subplot(2, 2, 2)\n",
    "    sns.regplot(x=merged_df[dimension_ranking], y=merged_df[\"Polar Rank Nearest R\"])\n",
    "    plt.xlabel('Ranking based on ' + str(Hofstede_dimensions))\n",
    "    plt.ylabel('Polar Rank based on nearest Random list')\n",
    "    plt.subplot(2, 2, 3)\n",
    "    sns.regplot(x=merged_df[dimension_ranking], y=merged_df[\"Polar Rank H\"])\n",
    "    plt.xlabel('Ranking based on ' + str(Hofstede_dimensions))\n",
    "    plt.ylabel('Polar Rank based on Human list')\n",
    "    plt.subplot(2, 2, 4)\n",
    "    sns.regplot(x=merged_df[dimension_ranking], y=merged_df[\"Polar Rank Nearest H\"])\n",
    "    plt.xlabel('Ranking based on ' + str(Hofstede_dimensions))\n",
    "    plt.ylabel('Polar Rank based on nearest Human list')\n",
    "    # set the spacing between subplots\n",
    "    plt.subplots_adjust(left=0.1,\n",
    "                      bottom=0.1, \n",
    "                      right=0.9, \n",
    "                      top=0.9, \n",
    "                      wspace=0.4, \n",
    "                      hspace=0.4)\n",
    "    print(\"\\n\\nPlot for the Correlation between ranking based on Hofstede Score and ranks of our 4 lists\")\n",
    "    plt.show() \n",
    "\n",
    "\n",
    "\n",
    "    # Below gives the plot for the Hofstede dimension score and our score we got for each of the 4 list\n",
    "    fig = go.Figure()\n",
    "    fig = make_subplots(rows=2, cols=2)\n",
    "    fig.add_trace(go.Bar(x=merged_df[\"Country\"] , y=merged_df[dim_index].astype(int), name = dim_index),1,1)  \n",
    "    fig.add_trace(go.Bar(x=merged_df[\"Country\"] , y=merged_df[\"Total Score Random\"].astype(int), name = \"Random Polar Score\"),1,1)  \n",
    "\n",
    "    fig.add_trace(go.Bar(x=merged_df[\"Country\"] , y=merged_df[dim_index].astype(int), name = dim_index),1,2)  \n",
    "    fig.add_trace(go.Bar(x=merged_df[\"Country\"] , y=merged_df[\"Total Score Nearest Random\"].astype(int), name = \"Nearest Random Polar Score\"),1,2)  \n",
    "\n",
    "    fig.add_trace(go.Bar(x=merged_df[\"Country\"] , y=merged_df[dim_index].astype(int), name = dim_index),2,1)  \n",
    "    fig.add_trace(go.Bar(x=merged_df[\"Country\"] , y=merged_df[\"Total Score Human\"].astype(int), name = \"Human Polar Score\"),2,1)  \n",
    "\n",
    "    fig.add_trace(go.Bar(x=merged_df[\"Country\"] , y=merged_df[dim_index].astype(int), name = dim_index),2,2)  \n",
    "    fig.add_trace(go.Bar(x=merged_df[\"Country\"] , y=merged_df[\"Total Score Nearest Human\"].astype(int), name = \"Nearest Human Polar Score\"),2,2) \n",
    "    print(\"\\n\\nPlot for the Hofstede dimension score and our score we got for each of the 4 list\")\n",
    "    fig.show() \n",
    "\n",
    "    # This displays the results of RMSE, MAE, Correlation of the 4 list to Hofstede's respective dimension\n",
    "    print(\"\\n\\nComparison Between the 4 list and \",Hofstede_dimensions)\n",
    "    display(eval_df)\n",
    "    \n",
    "    # This displays the results of RMSE, MAE, Correlation of the Random list to Nearest to Random list\n",
    "    print(\"\\n\\nComparison Between Random list to Nearest to Random list\")\n",
    "    display(eval_data_random)\n",
    "\n",
    "    # This displays the results of RMSE, MAE, Correlation of the Human list to Nearest to Human list\n",
    "    print(\"\\n\\nComparison Between Human list to nearest to Human list\")\n",
    "    display(eval_data_human)\n",
    "\n",
    "    # Show the correlation between every columns of the dataframe\n",
    "    print(\"\\n\\n\\nCorrelation Heat Map\")\n",
    "    corr = merged_df.corr()\n",
    "    display(corr.style.background_gradient(cmap='Pastel1', axis=None, vmin=-1, vmax=1).highlight_null(null_color='#f1f1f1').set_precision(2))\n",
    "\n",
    "\n",
    "  if polar_evaluation in \"1. Average Performance of the model over all the Hofstede's dimension\" :      \n",
    "    # Average rank \n",
    "    avgrank_random_list.append(eval_df.iloc[0,0])\n",
    "    avgrank_nearest_random_list.append(eval_df.iloc[1,0])\n",
    "    avgrank_human_list.append(eval_df.iloc[2,0])\n",
    "    avgrank_nearest_human_list.append(eval_df.iloc[3,0])\n",
    "\n",
    "    # Average score \n",
    "    avgscore_random_list.append(eval_df.iloc[0,2])\n",
    "    avgscore_nearest_random_list.append(eval_df.iloc[1,2])\n",
    "    avgscore_human_list.append(eval_df.iloc[2,2])\n",
    "    avgscore_nearest_human_list.append(eval_df.iloc[3,2])\n",
    "\n",
    "    # Average correlation rank \n",
    "    avg_corr_rank_random_list.append(eval_df.iloc[0,1])\n",
    "    avg_corr_rank_nearest_random_list.append(eval_df.iloc[1,1])\n",
    "    avg_corr_rank_human_list.append(eval_df.iloc[2,1])\n",
    "    avg_corr_rank_nearest_human_list.append(eval_df.iloc[3,1])\n",
    "\n",
    "    # Average correlation score \n",
    "    avg_corr_score_random_list.append(eval_df.iloc[0,3])\n",
    "    avg_corr_score_nearest_random_list.append(eval_df.iloc[1,3])\n",
    "    avg_corr_score_human_list.append(eval_df.iloc[2,3])\n",
    "    avg_corr_score_nearest_human_list.append(eval_df.iloc[3,3])\n",
    "\n",
    "\n",
    "    # Average eror between the Random List and Nearest 5 to Random List\n",
    "    MAE_random.append(mean_absolute_error(merged_df[\"Polar Rank R\"], merged_df[\"Polar Rank Nearest R\"]))\n",
    "    correlation_rank_random.append(merged_df[\"Polar Rank R\"].corr(merged_df[\"Polar Rank Nearest R\"]))\n",
    "    rmse_random.append(np.sqrt(mean_squared_error(merged_df[\"Total Score Random\"], merged_df[\"Total Score Nearest Random\"])))\n",
    "\n",
    "    # Average eror between the Human List and Nearest 5 to Human List\n",
    "    MAE_human.append(mean_absolute_error(merged_df[\"Polar Rank H\"], merged_df[\"Polar Rank Nearest H\"]))\n",
    "    correlation_rank_human.append(merged_df[\"Polar Rank H\"].corr(merged_df[\"Polar Rank Nearest H\"]))\n",
    "    rmse_human.append(np.sqrt(mean_squared_error(merged_df[\"Total Score Human\"], merged_df[\"Total Score Nearest Human\"])))\n",
    "\n",
    "\n",
    "\n",
    "if polar_evaluation in \"1. Average Performance of the model over all the Hofstede's dimension\" :\n",
    "\n",
    "  print(\"\\nRandom list - Average Mean Absolute Error of Rank: \", list_avg(avgrank_random_list))\n",
    "  print(\"Nearest Random list - Average Mean Absolute Error of Rank: \", list_avg(avgrank_nearest_random_list))\n",
    "  print(\"Human Made list - Average Mean Absolute Error of Rank: \", list_avg(avgrank_human_list))\n",
    "  print(\"Nearest Human Made list - Average Mean Absolute Error of Rank: \", list_avg(avgrank_nearest_human_list))\n",
    "\n",
    "  print(\"\\n\\n----------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "  print(\"\\nRandom list - Average RMSE of Score: \", list_avg(avgscore_random_list))\n",
    "  print(\"Nearest Random list - Average RMSE of Score: \", list_avg(avgscore_nearest_random_list))\n",
    "  print(\"Human Made list - Average RMSE of Score: \", list_avg(avgscore_human_list))\n",
    "  print(\"Nearest Human Made list - Average RMSE of Score: \", list_avg(avgscore_nearest_human_list))\n",
    "\n",
    "  print(\"\\n\\n----------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "  print(\"\\nRandom list - Average Correlation of Rank: \", list_avg(avg_corr_rank_random_list))\n",
    "  print(\"Nearest Random list - Average Correlation of Rank: \", list_avg(avg_corr_rank_nearest_random_list))\n",
    "  print(\"Human Made list - Average Correlation of Rank: \", list_avg(avg_corr_rank_human_list))\n",
    "  print(\"Nearest Human Made list - Average Correlation of Rank: \", list_avg(avg_corr_rank_nearest_human_list))\n",
    "\n",
    "  print(\"\\n\\n----------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "  print(\"\\nRandom list - Average Correlation of Score: \", list_avg(avg_corr_score_random_list))\n",
    "  print(\"Nearest Random list - Average Correlation of Score: \", list_avg(avg_corr_score_nearest_random_list))\n",
    "  print(\"Human Made list - Average Correlation of Score: \", list_avg(avg_corr_score_human_list))\n",
    "  print(\"Nearest Human Made list - Average Correlation of Score: \", list_avg(avg_corr_score_nearest_human_list))\n",
    "\n",
    "  print(\"\\n\\n----------------------------------------------------------------------------------------------------------\")\n",
    "  print(\"\\nBelow table displays the Average error between the Random List and Nearest Random list\\n\")\n",
    "  avg_eval_random = {\"Average MAE of Rank\" : list_avg(MAE_random),\n",
    "              \"Average Correlation\" : list_avg(correlation_rank_random),\n",
    "             \"Average RMSE of Score\" : list_avg(rmse_random)\n",
    "            }\n",
    "\n",
    "  avg_eval_random = pd.DataFrame(avg_eval_random, index =[\"Random List\"])\n",
    "  display(avg_eval_random)\n",
    "\n",
    "  print(\"\\n\\n----------------------------------------------------------------------------------------------------------\")\n",
    "  print(\"\\nBelow table displays the Average error between the Human List and Nearest Human list\\n\")\n",
    "  avg_eval_human = {\"Average MAE of Rank\" : list_avg(MAE_human),\n",
    "              \"Average Correlation\" : list_avg(correlation_rank_human),\n",
    "             \"Average RMSE of Score\" : list_avg(rmse_human)\n",
    "            }\n",
    "\n",
    "  avg_eval_human = pd.DataFrame(avg_eval_human, index =[\"Human List\"])\n",
    "  display(avg_eval_human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PolarWebE and Hofstede.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}